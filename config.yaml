logging:
  level: INFO

message_queue:
  backend: nats
  nats:
    servers:
      - nats://127.0.0.1:4222
    stream: snn_events
    subject: training.events
    durable: snn-worker
    connect: true
    timeout: 2.0
    allow_reconnect: true

training_worker:
  mode: tstep  # 可设为 tstep 或 fpt
  data:
    root: .data/datasets/mnist
    train: train.npz
    val: val.npz
    inputs_key: x
    labels_key: y
  network:
    input_dim: 784
    hidden_dim: 256
    output_dim: 10
  hyperparams:
    epochs: 10
    batch_size: 64
    lr: 0.001
    scheduler:
      type: cosine
      warmup_steps: 100
    weight_decay: 0.0
    truncation_steps: 4
    timesteps: 16
    seed: 42
    grad_clip: 1.0
    temperature:
      value: 1.0
      learnable: false
    logit_scale:
      value: 1.25
      learnable: false
    logit_scale_init: 1.25
    logit_scale_min: 0.5
    logit_scale_max: 3.0
    logit_scale_learnable: true
    head_hidden: 64
    head_momentum: 0.9
    unfreeze_at_conf: 0.13
    solver:
      type: anderson
      anderson_m: 4
      anderson_beta: 0.5
      K_schedule: auto
    rate_reg_lambda: 0.001
    rate_target: 0.2
    tstep_regularization:
      rate_reg_lambda: 0.001
      rate_target: 0.2
    g_apical:
      start: 0.5
      end: 0.2
    beta:
      start: 0.035
      end: 0.03
    v_th:
      start: -0.053
      end: -0.055
  neuron:
    dt: 0.001
    tau_soma: 0.02
    tau_apical: 0.03
    tau_basal: 0.03
    coupling_apical: 0.6
    coupling_basal: 0.6
    threshold: -0.054
    v_rest: -0.07
  nats:
    servers:
      - nats://127.0.0.1:4222
    stream: snn_training
    timeout: 2.0
    subjects:
      metrics: snn.metrics.training
      spikes: snn.spikes.layer
      logs: snn.ui.log.training

training_service:
  dataset: MNIST
  mode: fpt
  network_size: 128
  layers: 2
  epochs: 20
  lr: 0.001
  scheduler: warmup_cosine
  warmup_steps: 200
  min_lr_scale: 0.1
  min_lr: null
  weight_decay: 0.0001
  grad_clip: 1.0
  K: 4
  tol: 1.0e-5
  T: 12
  solver: anderson
  anderson_m: 4
  anderson_beta: 0.5
  K_schedule: auto
  temperature: 1.0
  logit_scale: 1.25
  logit_scale_learnable: false
  logit_scale_init: 1.25
  logit_scale_min: 0.5
  logit_scale_max: 3.0
  tstep_regularization:
    rate_reg_lambda: 0.001
    rate_target: 0.2
  rate_reg_lambda: 0.001
  rate_target: 0.2
  augment: true
  head_hidden: 64
  head_momentum: 0.9
  unfreeze_at_conf: 0.13
